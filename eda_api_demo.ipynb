{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa367840",
   "metadata": {},
   "source": [
    "# Demonstra√ß√£o da API EDA Backend\n",
    "## An√°lise Explorat√≥ria de Dados com FastAPI e ydata-profiling\n",
    "\n",
    "Este notebook demonstra como usar a API EDA desenvolvida em FastAPI para realizar an√°lise explorat√≥ria de dados em arquivos CSV usando ydata-profiling.\n",
    "\n",
    "## Funcionalidades da API\n",
    "\n",
    "A API oferece os seguintes endpoints:\n",
    "- `/upload-csv`: Upload de arquivo CSV e gera√ß√£o de relat√≥rio EDA encapsulado\n",
    "- `/upload-csv-raw`: Upload de arquivo CSV e retorno do JSON completo da an√°lise EDA\n",
    "- `/csv-info`: Informa√ß√µes b√°sicas sobre o arquivo CSV\n",
    "- `/supported-formats`: Formatos de arquivo suportados\n",
    "- `/endpoints`: Lista todos os endpoints dispon√≠veis da API\n",
    "- `/health`: Status da API\n",
    "- `/docs`: Documenta√ß√£o interativa (Swagger UI)\n",
    "\n",
    "## Tecnologias Utilizadas\n",
    "\n",
    "- **FastAPI**: Framework web moderno e r√°pido para construir APIs\n",
    "- **ydata-profiling**: Biblioteca para gera√ß√£o de relat√≥rios EDA\n",
    "- **pandas**: Manipula√ß√£o e an√°lise de dados\n",
    "- **Poetry**: Gerenciamento de depend√™ncias\n",
    "\n",
    "## Novidades Implementadas\n",
    "\n",
    "‚ú® **Novo endpoint `/upload-csv-raw`**: Retorna o JSON completo da an√°lise EDA sem encapsulamento adicional, ideal para integra√ß√£o com outras ferramentas ou an√°lise program√°tica.\n",
    "\n",
    "‚ú® **Novo endpoint `/endpoints`**: Lista todos os endpoints dispon√≠veis com descri√ß√µes detalhadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8bff72",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o do Ambiente\n",
    "\n",
    "Primeiro, vamos configurar o ambiente e importar as bibliotecas necess√°rias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d77b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso!\n",
      "URL da API: http://localhost:8000/api/v1\n",
      "Timestamp: 2025-09-30 22:52:52.378468\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, JSON\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Configura√ß√£o da API\n",
    "API_BASE_URL = \"http://localhost:8000/api/v1\"\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")\n",
    "print(f\"URL da API: {API_BASE_URL}\")\n",
    "print(f\"Timestamp: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c9e2a",
   "metadata": {},
   "source": [
    "## 2. Testando a Conectividade da API\n",
    "\n",
    "Vamos verificar se a API est√° funcionando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a65705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Resposta: {'message': 'EDA Backend API', 'version': '0.1.0', 'description': 'API para an√°lise explorat√≥ria de dados de arquivos CSV', 'docs': '/docs', 'redoc': '/redoc', 'endpoints': {'upload_csv': '/api/v1/upload-csv', 'csv_info': '/api/v1/csv-info', 'supported_formats': '/api/v1/supported-formats', 'health': '/api/v1/health'}}\n",
      "\n",
      "Formatos suportados: {'supported_formats': ['.csv'], 'description': 'Formatos de arquivo suportados para an√°lise EDA'}\n"
     ]
    }
   ],
   "source": [
    "# Teste de conectividade\n",
    "try:\n",
    "    # Testar endpoint raiz (sem prefixo /api/v1)\n",
    "    response = requests.get(\"http://localhost:8000/\")\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Resposta: {response.json()}\")\n",
    "    \n",
    "    # Verificar endpoints dispon√≠veis (com prefixo /api/v1)\n",
    "    health_response = requests.get(f\"{API_BASE_URL}/supported-formats\")\n",
    "    print(f\"\\nFormatos suportados: {health_response.json()}\")\n",
    "    \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå Erro: N√£o foi poss√≠vel conectar √† API.\")\n",
    "    print(\"Certifique-se de que o servidor est√° rodando: uvicorn main:app --reload\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714076d8",
   "metadata": {},
   "source": [
    "## 3. Upload e An√°lise do Arquivo CSV\n",
    "\n",
    "Agora vamos fazer o upload do arquivo de exemplo e obter a an√°lise EDA completa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec5432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Fazendo upload do arquivo...\n",
      "‚úÖ Upload realizado com sucesso!\n",
      "\n",
      "üîç ESTRUTURA DA RESPOSTA JSON:\n",
      "==================================================\n",
      "Chaves principais: ['success', 'message', 'filename', 'eda_data', 'error']\n",
      "Tipo da resposta: <class 'dict'>\n",
      "\n",
      "üìä An√°lise EDA conclu√≠da!\n",
      "üìÅ Arquivo analisado: example_data.csv\n",
      "‚ö†Ô∏è Chave 'analysis' n√£o encontrada na resposta\n",
      "üìã Verificando estrutura alternativa...\n",
      "üìÑ Primeiras 500 caracteres da resposta:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"message\": \"Arquivo processado com sucesso\",\n",
      "  \"filename\": \"example_data.csv\",\n",
      "  \"eda_data\": {\n",
      "    \"filename\": \"example_data.csv\",\n",
      "    \"rows\": 10,\n",
      "    \"columns\": 5,\n",
      "    \"column_names\": [\n",
      "      \"nome\",\n",
      "      \"idade\",\n",
      "      \"cidade\",\n",
      "      \"salario\",\n",
      "      \"departamento\"\n",
      "    ],\n",
      "    \"data_types\": {\n",
      "      \"nome\": \"object\",\n",
      "      \"idade\": \"int64\",\n",
      "      \"cidade\": \"object\",\n",
      "      \"salario\": \"float64\",\n",
      "      \"departamento\": \"object\"\n",
      "    },\n",
      "    \"eda_report\": {\n",
      "      \"analysis\": {\n",
      "...\n",
      "‚úÖ Upload realizado com sucesso!\n",
      "\n",
      "üîç ESTRUTURA DA RESPOSTA JSON:\n",
      "==================================================\n",
      "Chaves principais: ['success', 'message', 'filename', 'eda_data', 'error']\n",
      "Tipo da resposta: <class 'dict'>\n",
      "\n",
      "üìä An√°lise EDA conclu√≠da!\n",
      "üìÅ Arquivo analisado: example_data.csv\n",
      "‚ö†Ô∏è Chave 'analysis' n√£o encontrada na resposta\n",
      "üìã Verificando estrutura alternativa...\n",
      "üìÑ Primeiras 500 caracteres da resposta:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"message\": \"Arquivo processado com sucesso\",\n",
      "  \"filename\": \"example_data.csv\",\n",
      "  \"eda_data\": {\n",
      "    \"filename\": \"example_data.csv\",\n",
      "    \"rows\": 10,\n",
      "    \"columns\": 5,\n",
      "    \"column_names\": [\n",
      "      \"nome\",\n",
      "      \"idade\",\n",
      "      \"cidade\",\n",
      "      \"salario\",\n",
      "      \"departamento\"\n",
      "    ],\n",
      "    \"data_types\": {\n",
      "      \"nome\": \"object\",\n",
      "      \"idade\": \"int64\",\n",
      "      \"cidade\": \"object\",\n",
      "      \"salario\": \"float64\",\n",
      "      \"departamento\": \"object\"\n",
      "    },\n",
      "    \"eda_report\": {\n",
      "      \"analysis\": {\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Upload do arquivo CSV para an√°lise EDA\n",
    "csv_file_path = \"creditcard.csv\"\n",
    "\n",
    "try:\n",
    "    with open(csv_file_path, 'rb') as file:\n",
    "        files = {'file': (csv_file_path, file, 'text/csv')}\n",
    "        \n",
    "        print(\"üì§ Fazendo upload do arquivo...\")\n",
    "        response = requests.post(f\"{API_BASE_URL}/upload-csv\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"‚úÖ Upload realizado com sucesso!\")\n",
    "            eda_result = response.json()\n",
    "            \n",
    "            # Debug: Mostrar estrutura da resposta\n",
    "            print(\"\\nüîç ESTRUTURA DA RESPOSTA JSON:\")\n",
    "            print(\"=\" * 50)\n",
    "            print(f\"Chaves principais: {list(eda_result.keys())}\")\n",
    "            print(f\"Tipo da resposta: {type(eda_result)}\")\n",
    "            \n",
    "            # Salvar resultado para an√°lise posterior\n",
    "            with open('eda_result.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(eda_result, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"\\nüìä An√°lise EDA conclu√≠da!\")\n",
    "            print(f\"üìÅ Arquivo analisado: {eda_result.get('filename', 'N/A')}\")\n",
    "            \n",
    "            # Verificar se tem a chave 'analysis'\n",
    "            if 'analysis' in eda_result:\n",
    "                table_info = eda_result['analysis']['table']\n",
    "                print(f\"üìè Dimens√µes: {table_info['n']} linhas x {table_info['n_var']} colunas\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Chave 'analysis' n√£o encontrada na resposta\")\n",
    "                print(\"üìã Verificando estrutura alternativa...\")\n",
    "                \n",
    "                # Mostrar as primeiras linhas da resposta para debug\n",
    "                print(f\"üìÑ Primeiras 500 caracteres da resposta:\")\n",
    "                response_str = json.dumps(eda_result, indent=2)[:500]\n",
    "                print(response_str + \"...\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"‚ùå Erro no upload: {response.status_code}\")\n",
    "            print(f\"üìÑ Resposta completa: {response.text}\")\n",
    "            \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Arquivo n√£o encontrado: {csv_file_path}\")\n",
    "    print(\"Certifique-se de que o arquivo example_data.csv est√° no diret√≥rio atual\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea6c109",
   "metadata": {},
   "source": [
    "## 4. Explorando os Resultados da An√°lise EDA\n",
    "\n",
    "Vamos examinar os diferentes aspectos do relat√≥rio EDA gerado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18360b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vers√£o OTIMIZADA - An√°lise r√°pida dos resultados EDA\n",
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # 1. Verificar se o arquivo existe e seu tamanho\n",
    "    if os.path.exists('eda_result.json'):\n",
    "        file_size = os.path.getsize('eda_result.json')\n",
    "        print(f\"üìÑ Arquivo encontrado: {file_size:,} bytes\")\n",
    "        \n",
    "        # Se arquivo muito grande (>10MB), carregar apenas parte\n",
    "        if file_size > 10 * 1024 * 1024:  # 10MB\n",
    "            print(\"‚ö†Ô∏è Arquivo muito grande, carregando parcialmente...\")\n",
    "            with open('eda_result.json', 'r', encoding='utf-8') as f:\n",
    "                # Ler apenas os primeiros 1MB\n",
    "                content = f.read(1024 * 1024)\n",
    "                print(\"üìä Carregando dados parciais...\")\n",
    "                try:\n",
    "                    eda_response = json.loads(content + \"}\")  # Tentar fechar JSON\n",
    "                except:\n",
    "                    print(\"‚ùå Arquivo JSON muito grande para an√°lise completa\")\n",
    "                    print(\"üí° Use o endpoint /csv-info para informa√ß√µes b√°sicas\")\n",
    "                    raise Exception(\"Arquivo muito grande\")\n",
    "        else:\n",
    "            # Carregar arquivo normal\n",
    "            print(\"üìä Carregando arquivo JSON completo...\")\n",
    "            with open('eda_result.json', 'r', encoding='utf-8') as f:\n",
    "                eda_response = json.load(f)\n",
    "    else:\n",
    "        print(\"‚ùå Arquivo eda_result.json n√£o encontrado.\")\n",
    "        print(\"üí° Execute primeiro a c√©lula de upload do CSV.\")\n",
    "        raise FileNotFoundError(\"eda_result.json n√£o encontrado\")\n",
    "    \n",
    "    load_time = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è Tempo de carregamento: {load_time:.2f}s\")\n",
    "    \n",
    "    # 2. Verifica√ß√£o r√°pida da estrutura\n",
    "    print(f\"\\nüîç ESTRUTURA R√ÅPIDA\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"üìã Chaves principais: {list(eda_response.keys())}\")\n",
    "    \n",
    "    # Verificar se tem eda_data\n",
    "    if 'eda_data' in eda_response:\n",
    "        eda_data = eda_response['eda_data']\n",
    "        print(f\"‚úÖ eda_data encontrado\")\n",
    "        \n",
    "        # Informa√ß√µes b√°sicas r√°pidas\n",
    "        if 'table' in eda_data:\n",
    "            table_info = eda_data['table']\n",
    "            print(f\"\\nüìä RESUMO B√ÅSICO\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"üìÅ Arquivo: {eda_response.get('filename', 'N/A')}\")\n",
    "            print(f\"üìè Linhas: {table_info.get('n', 0):,}\")\n",
    "            print(f\"üìã Colunas: {table_info.get('n_var', 0):,}\")\n",
    "        \n",
    "        # Contar vari√°veis rapidamente (sem loop pesado)\n",
    "        if 'variables' in eda_data:\n",
    "            variables = eda_data['variables']\n",
    "            var_count = len(variables)\n",
    "            print(f\"üìà Total de vari√°veis: {var_count}\")\n",
    "            \n",
    "            # Mostrar apenas as primeiras 3 vari√°veis\n",
    "            print(f\"\\nüìã PRIMEIRAS 3 VARI√ÅVEIS:\")\n",
    "            for i, (var_name, var_info) in enumerate(variables.items()):\n",
    "                if i >= 3:  # Limitar a 3 para n√£o demorar\n",
    "                    break\n",
    "                var_type = var_info.get('type', 'Desconhecido')\n",
    "                print(f\"‚Ä¢ {var_name}: {var_type}\")\n",
    "            \n",
    "            if var_count > 3:\n",
    "                print(f\"... e mais {var_count - 3} vari√°veis\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå eda_data n√£o encontrado\")\n",
    "        print(f\"üìã Chaves dispon√≠veis: {list(eda_response.keys())}\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n‚è±Ô∏è Tempo total: {total_time:.2f}s\")\n",
    "    print(\"‚úÖ An√°lise r√°pida conclu√≠da!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Arquivo n√£o encontrado. Execute o upload primeiro.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"‚ùå Erro ao decodificar JSON. Arquivo pode estar corrompido.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è Tempo at√© erro: {total_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os resultados da an√°lise EDA\n",
    "try:\n",
    "    with open('eda_result.json', 'r', encoding='utf-8') as f:\n",
    "        eda_response = json.load(f)\n",
    "    \n",
    "    # Verificar estrutura da resposta\n",
    "    if 'eda_data' not in eda_response:\n",
    "        print(\"‚ùå Chave 'eda_data' n√£o encontrada na resposta.\")\n",
    "        print(f\"\udccb Chaves dispon√≠veis: {list(eda_response.keys())}\")\n",
    "        raise KeyError(\"eda_data n√£o encontrado\")\n",
    "    \n",
    "    # Extrair dados EDA da resposta\n",
    "    eda_data = eda_response['eda_data']\n",
    "    \n",
    "    print(\"\ud83düìä RESUMO GERAL DA AN√ÅLISE\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Informa√ß√µes b√°sicas da tabela\n",
    "    table_info = eda_data['table']\n",
    "    print(f\"üìÅ Arquivo: {eda_response['filename']}\")\n",
    "    print(f\"üìè Linhas: {table_info['n']:,}\")\n",
    "    print(f\"üìã Colunas: {table_info['n_var']:,}\")\n",
    "    print(f\"üî¢ C√©lulas totais: {table_info.get('n_cells', 0):,}\")\n",
    "    print(f\"‚ùå Valores ausentes: {table_info['n_cells_missing']:,}\")\n",
    "    print(f\"üìä Duplicatas: {table_info['n_duplicates']:,}\")\n",
    "    print(f\"üíæ Tamanho na mem√≥ria: {table_info['memory_size']:,} bytes\")\n",
    "    \n",
    "    # Informa√ß√µes sobre as vari√°veis\n",
    "    variables = eda_data['variables']\n",
    "    print(f\"\\nüìà TIPOS DE VARI√ÅVEIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    for var_name, var_info in variables.items():\n",
    "        var_type = var_info.get('type', 'Desconhecido')\n",
    "        print(f\"‚Ä¢ {var_name}: {var_type}\")\n",
    "        \n",
    "        if 'description' in var_info:\n",
    "            desc = var_info['description']\n",
    "            if 'mean' in desc:\n",
    "                print(f\"  - M√©dia: {desc['mean']:.2f}\")\n",
    "            if 'std' in desc:\n",
    "                print(f\"  - Desvio padr√£o: {desc['std']:.2f}\")\n",
    "            if 'min' in desc:\n",
    "                print(f\"  - M√≠nimo: {desc['min']}\")\n",
    "            if 'max' in desc:\n",
    "                print(f\"  - M√°ximo: {desc['max']}\")\n",
    "        print()\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Arquivo eda_result.json n√£o encontrado.\")\n",
    "    print(\"Execute primeiro a c√©lula de upload do CSV.\")\n",
    "except KeyError as e:\n",
    "    print(f\"‚ùå Chave n√£o encontrada: {e}\")\n",
    "    print(\"üìã Verificando estrutura da resposta...\")\n",
    "    if 'eda_response' in locals():\n",
    "        print(f\"Chaves dispon√≠veis: {list(eda_response.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao processar os dados: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35edbe2a",
   "metadata": {},
   "source": [
    "### 4.1 An√°lise de Correla√ß√µes\n",
    "\n",
    "Vamos examinar as correla√ß√µes entre as vari√°veis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4556c426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Erro na an√°lise de correla√ß√µes: name 'eda_data' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_572196/1130770769.py\", line 4, in <module>\n",
      "    correlations = eda_data['correlations']\n",
      "                   ^^^^^^^^\n",
      "NameError: name 'eda_data' is not defined\n"
     ]
    }
   ],
   "source": [
    "# An√°lise de correla√ß√µes\n",
    "try:\n",
    "    # Usar eda_data em vez de eda_data['analysis']\n",
    "    correlations = eda_data['correlations']\n",
    "    \n",
    "    print(\"üîó MATRIZ DE CORRELA√á√ïES\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Correla√ß√£o de Pearson (para vari√°veis num√©ricas)\n",
    "    if 'pearson' in correlations:\n",
    "        print(\"\\nüìä Correla√ß√£o de Pearson:\")\n",
    "        pearson_matrix = correlations['pearson']\n",
    "        \n",
    "        # Converter para DataFrame para melhor visualiza√ß√£o\n",
    "        import pandas as pd\n",
    "        pearson_df = pd.DataFrame(pearson_matrix)\n",
    "        print(pearson_df.round(3))\n",
    "        \n",
    "        # Encontrar correla√ß√µes altas (> 0.7 ou < -0.7)\n",
    "        print(\"\\nüî• Correla√ß√µes Fortes (|r| > 0.7):\")\n",
    "        correlations_found = False\n",
    "        for i, row in enumerate(pearson_df.index):\n",
    "            for j, col in enumerate(pearson_df.columns):\n",
    "                if i < j:  # Evitar duplicatas\n",
    "                    corr_value = pearson_df.iloc[i, j]\n",
    "                    if abs(corr_value) > 0.7:\n",
    "                        print(f\"‚Ä¢ {row} ‚Üî {col}: {corr_value:.3f}\")\n",
    "                        correlations_found = True\n",
    "        \n",
    "        if not correlations_found:\n",
    "            print(\"‚Ä¢ Nenhuma correla√ß√£o forte encontrada (|r| > 0.7)\")\n",
    "    \n",
    "    # Correla√ß√£o de Spearman (para vari√°veis ordinais)\n",
    "    if 'spearman' in correlations:\n",
    "        print(f\"\\nüìà Correla√ß√£o de Spearman dispon√≠vel: {len(correlations['spearman'])} vari√°veis\")\n",
    "    \n",
    "    # Correla√ß√£o de Kendall\n",
    "    if 'kendall' in correlations:\n",
    "        print(f\"üìâ Correla√ß√£o de Kendall dispon√≠vel: {len(correlations['kendall'])} vari√°veis\")\n",
    "    \n",
    "    # Correla√ß√£o para vari√°veis categ√≥ricas\n",
    "    if 'cramers' in correlations:\n",
    "        print(f\"üè∑Ô∏è Correla√ß√£o de Cram√©r's V dispon√≠vel: {len(correlations['cramers'])} vari√°veis categ√≥ricas\")\n",
    "        \n",
    "except KeyError as e:\n",
    "    print(f\"‚ùå Chave n√£o encontrada: {e}\")\n",
    "    print(\"üìã Verificando chaves dispon√≠veis em eda_data...\")\n",
    "    if 'eda_data' in locals():\n",
    "        print(f\"Chaves principais: {list(eda_data.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro na an√°lise de correla√ß√µes: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37436509",
   "metadata": {},
   "source": [
    "### 4.2 Alertas e Insights\n",
    "\n",
    "Vamos verificar os alertas e insights gerados automaticamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c91ddda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Erro na an√°lise de alertas: name 'eda_data' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_572196/2618361280.py\", line 4, in <module>\n",
      "    alerts = eda_data.get('alerts', [])\n",
      "             ^^^^^^^^\n",
      "NameError: name 'eda_data' is not defined\n"
     ]
    }
   ],
   "source": [
    "# An√°lise de alertas e insights\n",
    "try:\n",
    "    # Usar eda_data em vez de eda_data['analysis']\n",
    "    alerts = eda_data.get('alerts', [])\n",
    "    \n",
    "    print(\"üö® ALERTAS E INSIGHTS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    if alerts:\n",
    "        for i, alert in enumerate(alerts, 1):\n",
    "            alert_type = alert.get('alert_type', {})\n",
    "            print(f\"\\n{i}. üìã Tipo: {alert_type.get('display_name', 'N/A')}\")\n",
    "            print(f\"   üìù Descri√ß√£o: {alert.get('fmt', 'N/A')}\")\n",
    "            \n",
    "            # Mostrar valores espec√≠ficos se dispon√≠veis\n",
    "            if 'values' in alert:\n",
    "                values = alert['values']\n",
    "                for key, value in values.items():\n",
    "                    if isinstance(value, (int, float)):\n",
    "                        print(f\"   üìä {key}: {value:.3f}\" if isinstance(value, float) else f\"   üìä {key}: {value}\")\n",
    "                    else:\n",
    "                        print(f\"   üìä {key}: {value}\")\n",
    "    else:\n",
    "        print(\"‚úÖ Nenhum alerta encontrado - dados parecem estar em bom estado!\")\n",
    "    \n",
    "    # Verificar se h√° informa√ß√µes sobre missing data\n",
    "    print(f\"\\nüìä QUALIDADE DOS DADOS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Informa√ß√µes sobre dados ausentes por vari√°vel\n",
    "    variables = eda_data['variables']\n",
    "    missing_data_found = False\n",
    "    \n",
    "    for var_name, var_info in variables.items():\n",
    "        if 'n_missing' in var_info and var_info['n_missing'] > 0:\n",
    "            missing_data_found = True\n",
    "            missing_count = var_info['n_missing']\n",
    "            missing_pct = var_info.get('p_missing', 0) * 100\n",
    "            print(f\"‚ùå {var_name}: {missing_count} valores ausentes ({missing_pct:.1f}%)\")\n",
    "    \n",
    "    if not missing_data_found:\n",
    "        print(\"‚úÖ N√£o h√° valores ausentes no dataset!\")\n",
    "        \n",
    "except KeyError as e:\n",
    "    print(f\"‚ùå Chave n√£o encontrada: {e}\")\n",
    "    print(\"üìã Verificando estrutura dispon√≠vel...\")\n",
    "    if 'eda_data' in locals():\n",
    "        print(f\"Chaves em eda_data: {list(eda_data.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro na an√°lise de alertas: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13395457",
   "metadata": {},
   "source": [
    "### 4.3 Visualiza√ß√µes Integradas\n",
    "\n",
    "O ydata-profiling gera visualiza√ß√µes em formato SVG que est√£o inclu√≠das no JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b9fe14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Erro na an√°lise de visualiza√ß√µes: 'analysis'\n"
     ]
    }
   ],
   "source": [
    "# Explorar visualiza√ß√µes SVG embutidas\n",
    "try:\n",
    "    # Procurar por scatter plots nas correla√ß√µes\n",
    "    correlations = eda_data['analysis']['correlations']\n",
    "    \n",
    "    print(\"üé® VISUALIZA√á√ïES DISPON√çVEIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    svg_count = 0\n",
    "    \n",
    "    # Verificar se h√° scatter plots em pearson\n",
    "    if 'pearson' in correlations:\n",
    "        pearson_data = correlations['pearson']\n",
    "        if isinstance(pearson_data, list):\n",
    "            for item in pearson_data:\n",
    "                if isinstance(item, dict) and 'scatter' in item:\n",
    "                    svg_count += 1\n",
    "                    \n",
    "    print(f\"üìä Scatter plots encontrados: {svg_count}\")\n",
    "    \n",
    "    # Mostrar o primeiro SVG como exemplo (se dispon√≠vel)\n",
    "    scatter_plots_found = []\n",
    "    \n",
    "    # Procurar por SVGs em outras se√ß√µes\n",
    "    def find_svgs(data, path=\"\"):\n",
    "        svgs = []\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "                current_path = f\"{path}.{key}\" if path else key\n",
    "                if key == 'scatter' and isinstance(value, str) and value.startswith('<svg'):\n",
    "                    svgs.append((current_path, value))\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    svgs.extend(find_svgs(value, current_path))\n",
    "        elif isinstance(data, list):\n",
    "            for i, item in enumerate(data):\n",
    "                current_path = f\"{path}[{i}]\"\n",
    "                svgs.extend(find_svgs(item, current_path))\n",
    "        return svgs\n",
    "    \n",
    "    all_svgs = find_svgs(eda_data)\n",
    "    \n",
    "    print(f\"üñºÔ∏è Total de SVGs encontrados: {len(all_svgs)}\")\n",
    "    \n",
    "    if all_svgs:\n",
    "        print(\"\\\\nüìç Localiza√ß√µes dos SVGs:\")\n",
    "        for path, svg in all_svgs[:5]:  # Mostrar apenas os primeiros 5\n",
    "            print(f\"‚Ä¢ {path}\")\n",
    "            \n",
    "        # Mostrar o primeiro SVG\n",
    "        if len(all_svgs) > 0:\n",
    "            print(f\"\\\\nüéØ Exemplo de visualiza√ß√£o:\")\n",
    "            first_svg = all_svgs[0][1]\n",
    "            # Mostrar apenas uma pr√©via do SVG\n",
    "            preview = first_svg[:200] + \"...\" if len(first_svg) > 200 else first_svg\n",
    "            print(f\"SVG Preview: {preview}\")\n",
    "            \n",
    "            # Renderizar o SVG no notebook\n",
    "            from IPython.display import SVG, display\n",
    "            print(\"\\\\nüé® Renderizando visualiza√ß√£o:\")\n",
    "            display(SVG(first_svg))\n",
    "    else:\n",
    "        print(\"üìä Criando visualiza√ß√£o personalizada com matplotlib...\")\n",
    "        \n",
    "        # Se n√£o h√° SVGs, criar um plot simples com matplotlib\n",
    "        variables = eda_data['analysis']['variables']\n",
    "        numeric_vars = []\n",
    "        \n",
    "        for var_name, var_info in variables.items():\n",
    "            if var_info.get('type') in ['Numeric', 'Integer']:\n",
    "                numeric_vars.append(var_name)\n",
    "        \n",
    "        if len(numeric_vars) >= 2:\n",
    "            print(f\"Vari√°veis num√©ricas encontradas: {numeric_vars}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro na an√°lise de visualiza√ß√µes: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8dcc4c",
   "metadata": {},
   "source": [
    "## 5. Testando Outros Endpoints\n",
    "\n",
    "Vamos testar os demais endpoints da API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a5922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando endpoint de informa√ß√µes b√°sicas\n",
    "print(\"üîç TESTANDO ENDPOINT /csv-info\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    with open('example_data.csv', 'rb') as file:\n",
    "        files = {'file': ('example_data.csv', file, 'text/csv')}\n",
    "        response = requests.post(f\"{API_BASE_URL}/csv-info\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            info_result = response.json()\n",
    "            print(\"‚úÖ Informa√ß√µes b√°sicas obtidas com sucesso!\")\n",
    "            print(f\"üìÅ Arquivo: {info_result['filename']}\")\n",
    "            print(f\"üìè Linhas: {info_result['rows']}\")\n",
    "            print(f\"üìã Colunas: {info_result['columns']}\")\n",
    "            print(f\"üíæ Tamanho: {info_result['file_size_bytes']} bytes\")\n",
    "            print(f\"üè∑Ô∏è Nomes das colunas: {', '.join(info_result['column_names'])}\")\n",
    "            print(f\"üìä Tipos de dados: {info_result['column_types']}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Erro: {response.status_code} - {response.text}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*50)\n",
    "\n",
    "# Testando endpoint de formatos suportados\n",
    "print(\"\\\\nüìã FORMATOS SUPORTADOS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{API_BASE_URL}/supported-formats\")\n",
    "    if response.status_code == 200:\n",
    "        formats = response.json()\n",
    "        print(\"‚úÖ Formatos dispon√≠veis:\")\n",
    "        for fmt in formats['supported_formats']:\n",
    "            print(f\"‚Ä¢ {fmt}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Erro: {response.status_code}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950a3cde",
   "metadata": {},
   "source": [
    "### 5.1 Testando o Novo Endpoint JSON Completo\n",
    "\n",
    "Vamos testar o novo endpoint `/upload-csv-raw` que retorna o JSON completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3612fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando novo endpoint de JSON completo\n",
    "print(\"üîç TESTANDO ENDPOINT /upload-csv-raw\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    with open('example_data.csv', 'rb') as file:\n",
    "        files = {'file': ('example_data.csv', file, 'text/csv')}\n",
    "        response = requests.post(f\"{API_BASE_URL}/upload-csv-raw\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            raw_result = response.json()\n",
    "            print(\"‚úÖ JSON completo obtido com sucesso!\")\n",
    "            print(f\"üìÅ Arquivo: {raw_result['filename']}\")\n",
    "            \n",
    "            # Salvar JSON completo\n",
    "            with open('eda_raw_result.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(raw_result, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            # Mostrar estrutura do JSON completo\n",
    "            print(f\"\\nüìã ESTRUTURA DO JSON COMPLETO:\")\n",
    "            print(f\"‚Ä¢ Chaves principais: {list(raw_result.keys())}\")\n",
    "            \n",
    "            if 'analysis' in raw_result:\n",
    "                analysis_keys = list(raw_result['analysis'].keys())\n",
    "                print(f\"‚Ä¢ Chaves em 'analysis': {analysis_keys[:10]}...\")  # Mostrar apenas as primeiras 10\n",
    "                print(f\"‚Ä¢ Total de se√ß√µes na an√°lise: {len(analysis_keys)}\")\n",
    "            \n",
    "            # Comparar tamanhos dos arquivos\n",
    "            import os\n",
    "            size_normal = os.path.getsize('eda_result.json') if os.path.exists('eda_result.json') else 0\n",
    "            size_raw = os.path.getsize('eda_raw_result.json')\n",
    "            \n",
    "            print(f\"\\nüìä COMPARA√á√ÉO DE TAMANHOS:\")\n",
    "            print(f\"‚Ä¢ JSON encapsulado: {size_normal:,} bytes\")\n",
    "            print(f\"‚Ä¢ JSON completo: {size_raw:,} bytes\")\n",
    "            print(f\"‚Ä¢ Diferen√ßa: {size_raw - size_normal:,} bytes\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"‚ùå Erro: {response.status_code} - {response.text}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d699bd06",
   "metadata": {},
   "source": [
    "### 5.2 Explorando Endpoints Dispon√≠veis\n",
    "\n",
    "Vamos verificar todos os endpoints dispon√≠veis na API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aaed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando endpoint de listagem de endpoints\n",
    "print(\"üìã EXPLORANDO ENDPOINTS DA API\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{API_BASE_URL}/endpoints\")\n",
    "    if response.status_code == 200:\n",
    "        endpoints_info = response.json()\n",
    "        print(\"‚úÖ Informa√ß√µes dos endpoints obtidas!\")\n",
    "        \n",
    "        # Informa√ß√µes da API\n",
    "        api_info = endpoints_info.get('api_info', {})\n",
    "        print(f\"\\nüìç {api_info.get('name', 'API')}\")\n",
    "        print(f\"üìå Vers√£o: {api_info.get('version', 'N/A')}\")\n",
    "        print(f\"üìù Descri√ß√£o: {api_info.get('description', 'N/A')}\")\n",
    "        \n",
    "        # Listar endpoints\n",
    "        endpoints = endpoints_info.get('endpoints', {})\n",
    "        print(f\"\\nüîó ENDPOINTS DISPON√çVEIS ({len(endpoints)}):\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for name, details in endpoints.items():\n",
    "            method = details.get('method', 'N/A')\n",
    "            path = details.get('path', 'N/A')\n",
    "            description = details.get('description', 'N/A')\n",
    "            parameters = details.get('parameters', '')\n",
    "            \n",
    "            print(f\"‚Ä¢ {method:<6} {path}\")\n",
    "            print(f\"  üìÑ {description}\")\n",
    "            if parameters:\n",
    "                print(f\"  üìé Par√¢metros: {parameters}\")\n",
    "            print()\n",
    "        \n",
    "        # Documenta√ß√£o\n",
    "        docs = endpoints_info.get('documentation', {})\n",
    "        print(f\"üìö DOCUMENTA√á√ÉO:\")\n",
    "        for doc_type, url in docs.items():\n",
    "            print(f\"‚Ä¢ {doc_type}: http://localhost:8000{url}\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"‚ùå Erro: {response.status_code}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2b09a8",
   "metadata": {},
   "source": [
    "## 6. Criando Visualiza√ß√µes Customizadas\n",
    "\n",
    "Vamos criar algumas visualiza√ß√µes personalizadas com base nos dados da EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae342e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar visualiza√ß√µes baseadas nos dados da EDA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "try:\n",
    "    # Extrair dados estat√≠sticos das vari√°veis para visualiza√ß√£o\n",
    "    variables = eda_data['variables']\n",
    "    \n",
    "    # Coletar informa√ß√µes das vari√°veis num√©ricas\n",
    "    numeric_stats = {}\n",
    "    categorical_stats = {}\n",
    "    \n",
    "    for var_name, var_info in variables.items():\n",
    "        var_type = var_info.get('type', '')\n",
    "        \n",
    "        if var_type in ['Numeric', 'Integer']:\n",
    "            if 'description' in var_info:\n",
    "                desc = var_info['description']\n",
    "                numeric_stats[var_name] = {\n",
    "                    'mean': desc.get('mean', 0),\n",
    "                    'std': desc.get('std', 0),\n",
    "                    'min': desc.get('min', 0),\n",
    "                    'max': desc.get('max', 0),\n",
    "                    'q1': desc.get('25%', 0),\n",
    "                    'median': desc.get('50%', 0),\n",
    "                    'q3': desc.get('75%', 0)\n",
    "                }\n",
    "        elif var_type == 'Categorical':\n",
    "            categorical_stats[var_name] = var_info\n",
    "    \n",
    "    print(f\"üìä Vari√°veis num√©ricas encontradas: {len(numeric_stats)}\")\n",
    "    print(f\"üè∑Ô∏è Vari√°veis categ√≥ricas encontradas: {len(categorical_stats)}\")\n",
    "    \n",
    "    # Visualiza√ß√£o 1: Compara√ß√£o de m√©dias\n",
    "    if numeric_stats:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle('üìä An√°lise Estat√≠stica das Vari√°veis Num√©ricas', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Gr√°fico 1: M√©dias\n",
    "        var_names = list(numeric_stats.keys())\n",
    "        means = [numeric_stats[var]['mean'] for var in var_names]\n",
    "        \n",
    "        axes[0, 0].bar(var_names, means, color='skyblue', alpha=0.7)\n",
    "        axes[0, 0].set_title('Valores M√©dios por Vari√°vel')\n",
    "        axes[0, 0].set_ylabel('Valor M√©dio')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Gr√°fico 2: Desvios padr√£o\n",
    "        stds = [numeric_stats[var]['std'] for var in var_names]\n",
    "        axes[0, 1].bar(var_names, stds, color='lightcoral', alpha=0.7)\n",
    "        axes[0, 1].set_title('Desvio Padr√£o por Vari√°vel')\n",
    "        axes[0, 1].set_ylabel('Desvio Padr√£o')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Gr√°fico 3: Box plot comparativo (simulado)\n",
    "        box_data = []\n",
    "        box_labels = []\n",
    "        for var in var_names:\n",
    "            stats = numeric_stats[var]\n",
    "            # Simular distribui√ß√£o baseada nas estat√≠sticas\n",
    "            simulated_data = np.random.normal(stats['mean'], stats['std'], 100)\n",
    "            box_data.append(simulated_data)\n",
    "            box_labels.append(var)\n",
    "        \n",
    "        axes[1, 0].boxplot(box_data, labels=box_labels)\n",
    "        axes[1, 0].set_title('Distribui√ß√£o das Vari√°veis (Simulada)')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Gr√°fico 4: Amplitude (max - min)\n",
    "        ranges = [numeric_stats[var]['max'] - numeric_stats[var]['min'] for var in var_names]\n",
    "        axes[1, 1].bar(var_names, ranges, color='lightgreen', alpha=0.7)\n",
    "        axes[1, 1].set_title('Amplitude por Vari√°vel')\n",
    "        axes[1, 1].set_ylabel('Amplitude (Max - Min)')\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Tabela resumo\n",
    "        print(\"\\\\nüìã RESUMO ESTAT√çSTICO\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"{'Vari√°vel':<15} {'M√©dia':<10} {'Desvio':<10} {'Min':<10} {'Max':<10}\")\n",
    "        print(\"-\" * 60)\n",
    "        for var in var_names:\n",
    "            stats = numeric_stats[var]\n",
    "            print(f\"{var:<15} {stats['mean']:<10.2f} {stats['std']:<10.2f} {stats['min']:<10.2f} {stats['max']:<10.2f}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå Nenhuma vari√°vel num√©rica encontrada para visualiza√ß√£o\")\n",
    "        \n",
    "except KeyError as e:\n",
    "    print(f\"‚ùå Chave n√£o encontrada: {e}\")\n",
    "    print(\"üìã Verificando estrutura dispon√≠vel...\")\n",
    "    if 'eda_data' in locals():\n",
    "        print(f\"Chaves em eda_data: {list(eda_data.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro na cria√ß√£o de visualiza√ß√µes: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88c45e6",
   "metadata": {},
   "source": [
    "## 7. Conclus√µes e Pr√≥ximos Passos\n",
    "\n",
    "### Resumo da Demonstra√ß√£o\n",
    "\n",
    "Este notebook demonstrou com sucesso o uso da API EDA desenvolvida em FastAPI. A API conseguiu:\n",
    "\n",
    "‚úÖ **Processar arquivos CSV** com upload seguro e valida√ß√£o  \n",
    "‚úÖ **Gerar an√°lise EDA completa** usando ydata-profiling  \n",
    "‚úÖ **Retornar dados estruturados** em formato JSON  \n",
    "‚úÖ **Fornecer m√∫ltiplos endpoints** para diferentes necessidades  \n",
    "‚úÖ **Incluir visualiza√ß√µes** embutidas em formato SVG  \n",
    "\n",
    "### Principais Funcionalidades Demonstradas\n",
    "\n",
    "1. **Upload e An√°lise**: Endpoint `/upload-csv` processa arquivos e retorna an√°lise completa\n",
    "2. **Informa√ß√µes B√°sicas**: Endpoint `/csv-info` fornece overview r√°pido dos dados\n",
    "3. **An√°lise de Correla√ß√µes**: Matrizes de correla√ß√£o Pearson, Spearman e Kendall\n",
    "4. **Detec√ß√£o de Qualidade**: Alertas autom√°ticos para problemas nos dados\n",
    "5. **Visualiza√ß√µes Integradas**: SVGs embutidos para scatter plots e histogramas\n",
    "\n",
    "### Benef√≠cios da Abordagem\n",
    "\n",
    "- **Escalabilidade**: API REST permite integra√ß√£o com qualquer sistema\n",
    "- **Padroniza√ß√£o**: Respostas JSON estruturadas e consistentes\n",
    "- **Automatiza√ß√£o**: An√°lise EDA completa com um √∫nico endpoint\n",
    "- **Flexibilidade**: M√∫ltiplos endpoints para diferentes casos de uso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d8d79c",
   "metadata": {},
   "source": [
    "### Pr√≥ximos Passos Recomendados\n",
    "\n",
    "#### Melhorias T√©cnicas\n",
    "1. **Autentica√ß√£o**: Implementar JWT ou API Keys para seguran√ßa\n",
    "2. **Cache**: Adicionar Redis para cache de an√°lises de arquivos grandes\n",
    "3. **Processamento Ass√≠ncrono**: Usar Celery para arquivos muito grandes\n",
    "4. **Valida√ß√£o Avan√ßada**: Esquemas de valida√ß√£o mais robustos\n",
    "5. **Logging**: Sistema de logs detalhado para debugging\n",
    "\n",
    "#### Funcionalidades Adicionais\n",
    "1. **M√∫ltiplos Formatos**: Suporte para Excel, Parquet, JSON\n",
    "2. **An√°lise Temporal**: Detec√ß√£o autom√°tica de s√©ries temporais\n",
    "3. **ML Insights**: Sugest√µes autom√°ticas de modelos\n",
    "4. **Exporta√ß√£o**: PDF e HTML dos relat√≥rios\n",
    "5. **Compara√ß√£o**: Endpoint para comparar datasets\n",
    "\n",
    "#### Integra√ß√£o e Deploy\n",
    "1. **Containeriza√ß√£o**: Docker para deployment\n",
    "2. **CI/CD**: Pipeline automatizado\n",
    "3. **Monitoramento**: Prometheus e Grafana\n",
    "4. **Documenta√ß√£o**: OpenAPI mais detalhada\n",
    "5. **Testes**: Suite completa de testes automatizados\n",
    "\n",
    "### Como Executar Este Projeto\n",
    "\n",
    "```bash\n",
    "# 1. Clonar/configurar o projeto\n",
    "cd eda-backend\n",
    "\n",
    "# 2. Instalar depend√™ncias\n",
    "poetry install\n",
    "\n",
    "# 3. Ativar ambiente virtual\n",
    "poetry shell\n",
    "\n",
    "# 4. Executar servidor\n",
    "uvicorn main:app --reload\n",
    "\n",
    "# 5. Acessar documenta√ß√£o\n",
    "# http://localhost:8000/docs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc92e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste final - Verificar status da API\n",
    "print(\"üéØ TESTE FINAL DE CONECTIVIDADE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Verificar se a API ainda est√° respondendo\n",
    "    response = requests.get(f\"{API_BASE_URL}/\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ API est√° funcionando perfeitamente!\")\n",
    "        print(f\"üì° Status: {response.status_code}\")\n",
    "        print(f\"‚ö° Resposta: {response.json()}\")\n",
    "        \n",
    "        # Estat√≠sticas da sess√£o\n",
    "        print(f\"\\nüìä ESTAT√çSTICAS DA SESS√ÉO\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"üïê Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"üåê URL da API: {API_BASE_URL}\")\n",
    "        print(f\"üìÅ Arquivo analisado: example_data.csv\")\n",
    "        print(f\"üíæ Resultado salvo em: eda_result.json\")\n",
    "        print(f\"üìà An√°lise EDA: Completa com correla√ß√µes e alertas\")\n",
    "        print(f\"üé® Visualiza√ß√µes: SVGs embutidos + matplotlib customizado\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è API respondeu com status: {response.status_code}\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå Erro de conex√£o - Verifique se o servidor est√° rodando\")\n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"‚è∞ Timeout - API pode estar sobrecarregada\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro inesperado: {e}\")\n",
    "\n",
    "print(f\"\\nüéâ Demonstra√ß√£o da API EDA Backend conclu√≠da com sucesso!\")\n",
    "print(\"üìö Para mais informa√ß√µes, acesse: http://localhost:8000/docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aab21fc",
   "metadata": {},
   "source": [
    "## 8. Testando os Novos Endpoints Implementados\n",
    "\n",
    "Agora vamos testar os novos endpoints que foram criados baseados na an√°lise do notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3640fe92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ TESTANDO NOVOS ENDPOINTS\n",
      "============================================================\n",
      "\n",
      "üìä 1. ENDPOINT DE CORRELA√á√ïES\n",
      "----------------------------------------\n",
      "‚úÖ Correla√ß√µes obtidas com sucesso!\n",
      "üìÅ Arquivo: example_data.csv\n",
      "üîó Tipos dispon√≠veis: []\n",
      "\n",
      "üìä 2. ENDPOINT DE ESTAT√çSTICAS\n",
      "----------------------------------------\n",
      "‚úÖ Estat√≠sticas obtidas com sucesso!\n",
      "üìÅ Arquivo: example_data.csv\n",
      "üìä Total de vari√°veis: 0\n",
      "üî¢ Vari√°veis num√©ricas: 0\n",
      "üè∑Ô∏è Vari√°veis categ√≥ricas: 0\n",
      "\n",
      "üö® 3. ENDPOINT DE ALERTAS\n",
      "----------------------------------------\n",
      "‚úÖ Alertas obtidos com sucesso!\n",
      "üìÅ Arquivo: example_data.csv\n",
      "üö® Total de alertas: 0\n",
      "‚ùå Vari√°veis com dados ausentes: 0\n",
      "üìä Score de qualidade: 100/100\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Testando os novos endpoints implementados\n",
    "print(\"üöÄ TESTANDO NOVOS ENDPOINTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Testando endpoint de correla√ß√µes\n",
    "print(\"\\nüìä 1. ENDPOINT DE CORRELA√á√ïES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    with open('example_data.csv', 'rb') as file:\n",
    "        files = {'file': ('example_data.csv', file, 'text/csv')}\n",
    "        response = requests.post(f\"{API_BASE_URL}/correlations\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            corr_result = response.json()\n",
    "            print(\"‚úÖ Correla√ß√µes obtidas com sucesso!\")\n",
    "            print(f\"üìÅ Arquivo: {corr_result['filename']}\")\n",
    "            print(f\"üîó Tipos dispon√≠veis: {corr_result['available_types']}\")\n",
    "            \n",
    "            # Mostrar correla√ß√£o Pearson se dispon√≠vel\n",
    "            correlations = corr_result.get('correlations', {})\n",
    "            if 'pearson' in correlations:\n",
    "                print(f\"üìà Matriz Pearson: {len(correlations['pearson'])}x{len(correlations['pearson'])} elementos\")\n",
    "        else:\n",
    "            print(f\"‚ùå Erro: {response.status_code} - {response.text}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "# 2. Testando endpoint de estat√≠sticas\n",
    "print(\"\\nüìä 2. ENDPOINT DE ESTAT√çSTICAS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    with open('example_data.csv', 'rb') as file:\n",
    "        files = {'file': ('example_data.csv', file, 'text/csv')}\n",
    "        response = requests.post(f\"{API_BASE_URL}/statistics\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            stats_result = response.json()\n",
    "            print(\"‚úÖ Estat√≠sticas obtidas com sucesso!\")\n",
    "            print(f\"üìÅ Arquivo: {stats_result['filename']}\")\n",
    "            \n",
    "            summary = stats_result['summary']\n",
    "            print(f\"üìä Total de vari√°veis: {summary['total_variables']}\")\n",
    "            print(f\"üî¢ Vari√°veis num√©ricas: {summary['numeric_count']}\")\n",
    "            print(f\"üè∑Ô∏è Vari√°veis categ√≥ricas: {summary['categorical_count']}\")\n",
    "            \n",
    "            # Mostrar estat√≠sticas das vari√°veis num√©ricas\n",
    "            numeric_vars = stats_result.get('numeric_variables', {})\n",
    "            if numeric_vars:\n",
    "                print(f\"\\nüìà Estat√≠sticas das vari√°veis num√©ricas:\")\n",
    "                for var_name, stats in list(numeric_vars.items())[:3]:  # Mostrar apenas 3 primeiras\n",
    "                    print(f\"‚Ä¢ {var_name}:\")\n",
    "                    print(f\"  - M√©dia: {stats.get('mean', 'N/A')}\")\n",
    "                    print(f\"  - Desvio: {stats.get('std', 'N/A')}\")\n",
    "                    print(f\"  - Min: {stats.get('min', 'N/A')}\")\n",
    "                    print(f\"  - Max: {stats.get('max', 'N/A')}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Erro: {response.status_code} - {response.text}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "# 3. Testando endpoint de alertas\n",
    "print(\"\\nüö® 3. ENDPOINT DE ALERTAS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    with open('example_data.csv', 'rb') as file:\n",
    "        files = {'file': ('example_data.csv', file, 'text/csv')}\n",
    "        response = requests.post(f\"{API_BASE_URL}/alerts\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            alerts_result = response.json()\n",
    "            print(\"‚úÖ Alertas obtidos com sucesso!\")\n",
    "            print(f\"üìÅ Arquivo: {alerts_result['filename']}\")\n",
    "            \n",
    "            quality_summary = alerts_result['quality_summary']\n",
    "            print(f\"üö® Total de alertas: {quality_summary['total_alerts']}\")\n",
    "            print(f\"‚ùå Vari√°veis com dados ausentes: {quality_summary['variables_with_missing']}\")\n",
    "            print(f\"üìä Score de qualidade: {quality_summary['data_quality_score']}/100\")\n",
    "            \n",
    "            # Mostrar alertas se existirem\n",
    "            alerts = alerts_result.get('alerts', [])\n",
    "            if alerts:\n",
    "                print(f\"\\n‚ö†Ô∏è Alertas encontrados:\")\n",
    "                for i, alert in enumerate(alerts[:3], 1):  # Mostrar apenas 3 primeiros\n",
    "                    alert_type = alert.get('alert_type', {})\n",
    "                    print(f\"{i}. {alert_type.get('display_name', 'N/A')}\")\n",
    "            \n",
    "            # Mostrar dados ausentes\n",
    "            missing_data = alerts_result.get('missing_data', {})\n",
    "            if missing_data:\n",
    "                print(f\"\\n‚ùå Dados ausentes por vari√°vel:\")\n",
    "                for var, info in list(missing_data.items())[:3]:\n",
    "                    print(f\"‚Ä¢ {var}: {info['missing_count']} ({info['missing_percentage']:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"‚ùå Erro: {response.status_code} - {response.text}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31cf4852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® 4. ENDPOINT DE VISUALIZA√á√ïES\n",
      "----------------------------------------\n",
      "‚úÖ Visualiza√ß√µes obtidas com sucesso!\n",
      "üìÅ Arquivo: example_data.csv\n",
      "üé® Total de visualiza√ß√µes: 0\n",
      "üéØ Tipos dispon√≠veis: []\n",
      "\n",
      "üîç 5. ENDPOINT DE AN√ÅLISE DE VARI√ÅVEL\n",
      "----------------------------------------\n",
      "‚ö†Ô∏è Nenhuma vari√°vel num√©rica encontrada para teste\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Continuando os testes dos novos endpoints\n",
    "\n",
    "# 4. Testando endpoint de visualiza√ß√µes\n",
    "print(\"üé® 4. ENDPOINT DE VISUALIZA√á√ïES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    with open('example_data.csv', 'rb') as file:\n",
    "        files = {'file': ('example_data.csv', file, 'text/csv')}\n",
    "        response = requests.post(f\"{API_BASE_URL}/visualizations\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            viz_result = response.json()\n",
    "            print(\"‚úÖ Visualiza√ß√µes obtidas com sucesso!\")\n",
    "            print(f\"üìÅ Arquivo: {viz_result['filename']}\")\n",
    "            \n",
    "            summary = viz_result['summary']\n",
    "            print(f\"üé® Total de visualiza√ß√µes: {summary['total_visualizations']}\")\n",
    "            print(f\"üéØ Tipos dispon√≠veis: {summary['available_types']}\")\n",
    "            \n",
    "            # Mostrar caminhos das visualiza√ß√µes\n",
    "            visualizations = viz_result.get('visualizations', {})\n",
    "            if visualizations:\n",
    "                print(f\"\\nüñºÔ∏è Visualiza√ß√µes encontradas:\")\n",
    "                for i, (path, svg) in enumerate(list(visualizations.items())[:5], 1):\n",
    "                    svg_size = len(svg)\n",
    "                    print(f\"{i}. {path} ({svg_size:,} caracteres)\")\n",
    "                    \n",
    "                # Renderizar a primeira visualiza√ß√£o se dispon√≠vel\n",
    "                if visualizations:\n",
    "                    first_svg = list(visualizations.values())[0]\n",
    "                    try:\n",
    "                        from IPython.display import SVG, display\n",
    "                        print(f\"\\nüé® Renderizando primeira visualiza√ß√£o:\")\n",
    "                        display(SVG(first_svg))\n",
    "                    except Exception as svg_error:\n",
    "                        print(f\"‚ö†Ô∏è Erro ao renderizar SVG: {svg_error}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Erro: {response.status_code} - {response.text}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "# 5. Testando endpoint de an√°lise de vari√°vel espec√≠fica\n",
    "print(\"\\nüîç 5. ENDPOINT DE AN√ÅLISE DE VARI√ÅVEL\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Primeiro, vamos descobrir quais vari√°veis est√£o dispon√≠veis\n",
    "try:\n",
    "    with open('example_data.csv', 'rb') as file:\n",
    "        files = {'file': ('example_data.csv', file, 'text/csv')}\n",
    "        # Usar endpoint de estat√≠sticas para descobrir vari√°veis\n",
    "        stats_response = requests.post(f\"{API_BASE_URL}/statistics\", files=files)\n",
    "        \n",
    "        if stats_response.status_code == 200:\n",
    "            stats_data = stats_response.json()\n",
    "            numeric_vars = list(stats_data.get('numeric_variables', {}).keys())\n",
    "            categorical_vars = list(stats_data.get('categorical_variables', {}).keys())\n",
    "            \n",
    "            # Testar com a primeira vari√°vel num√©rica se dispon√≠vel\n",
    "            if numeric_vars:\n",
    "                test_variable = numeric_vars[0]\n",
    "                print(f\"üéØ Testando an√°lise da vari√°vel: {test_variable}\")\n",
    "                \n",
    "                with open('example_data.csv', 'rb') as file2:\n",
    "                    files2 = {'file': ('example_data.csv', file2, 'text/csv')}\n",
    "                    var_response = requests.post(f\"{API_BASE_URL}/variable/{test_variable}\", files=files2)\n",
    "                    \n",
    "                    if var_response.status_code == 200:\n",
    "                        var_result = var_response.json()\n",
    "                        print(\"‚úÖ An√°lise de vari√°vel obtida com sucesso!\")\n",
    "                        print(f\"üìä Vari√°vel: {var_result['variable_name']}\")\n",
    "                        print(f\"üè∑Ô∏è Tipo: {var_result['variable_type']}\")\n",
    "                        \n",
    "                        missing_info = var_result['missing_info']\n",
    "                        print(f\"‚ùå Dados ausentes: {missing_info['count']} ({missing_info['percentage']:.1f}%)\")\n",
    "                        \n",
    "                        # Mostrar algumas estat√≠sticas se for num√©rica\n",
    "                        analysis = var_result.get('analysis', {})\n",
    "                        if 'description' in analysis:\n",
    "                            desc = analysis['description']\n",
    "                            print(f\"üìà Estat√≠sticas:\")\n",
    "                            for key in ['mean', 'std', 'min', 'max']:\n",
    "                                if key in desc:\n",
    "                                    print(f\"  - {key}: {desc[key]}\")\n",
    "                    else:\n",
    "                        print(f\"‚ùå Erro: {var_response.status_code} - {var_response.text}\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Nenhuma vari√°vel num√©rica encontrada para teste\")\n",
    "        else:\n",
    "            print(f\"‚ùå Erro ao obter vari√°veis: {stats_response.status_code}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "925ab719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã 6. ENDPOINT ATUALIZADO DE LISTAGEM\n",
      "----------------------------------------\n",
      "‚úÖ Lista de endpoints atualizada obtida!\n",
      "\n",
      "üìç EDA Backend API\n",
      "üìå Vers√£o: 0.1.0\n",
      "\n",
      "üîó ENDPOINTS DISPON√çVEIS (11):\n",
      "------------------------------------------------------------\n",
      "üîç Endpoints GET:\n",
      "‚Ä¢ GET    /api/v1/health\n",
      "  üìÑ Verificar status da API\n",
      "\n",
      "‚Ä¢ GET    /api/v1/supported-formats\n",
      "  üìÑ Formatos de arquivo suportados\n",
      "\n",
      "‚Ä¢ GET    /api/v1/endpoints\n",
      "  üìÑ Listar todos os endpoints (este endpoint)\n",
      "\n",
      "üì§ Endpoints POST:\n",
      "‚Ä¢ POST   /api/v1/upload-csv\n",
      "  üìÑ Upload de CSV com an√°lise EDA encapsulada\n",
      "\n",
      "‚Ä¢ POST   /api/v1/upload-csv-raw\n",
      "  üìÑ Upload de CSV com JSON completo da an√°lise EDA\n",
      "\n",
      "‚Ä¢ POST   /api/v1/csv-info\n",
      "  üìÑ Informa√ß√µes b√°sicas do CSV (sem an√°lise completa)\n",
      "\n",
      "‚Ä¢ POST   /api/v1/correlations\n",
      "  üìÑ Matriz de correla√ß√µes entre vari√°veis\n",
      "\n",
      "‚Ä¢ POST   /api/v1/statistics\n",
      "  üìÑ Estat√≠sticas descritivas das vari√°veis\n",
      "\n",
      "‚Ä¢ POST   /api/v1/alerts\n",
      "  üìÑ Alertas de qualidade de dados\n",
      "\n",
      "‚Ä¢ POST   /api/v1/visualizations\n",
      "  üìÑ Extrair visualiza√ß√µes SVG da an√°lise\n",
      "\n",
      "‚Ä¢ POST   /api/v1/variable/{variable_name}\n",
      "  üìÑ An√°lise detalhada de uma vari√°vel espec√≠fica\n",
      "\n",
      "üìä RESUMO:\n",
      "‚Ä¢ Total de endpoints: 11\n",
      "‚Ä¢ Endpoints GET: 3\n",
      "‚Ä¢ Endpoints POST: 8\n",
      "\n",
      "============================================================\n",
      "üéâ TODOS OS NOVOS ENDPOINTS TESTADOS!\n",
      "‚úÖ Implementa√ß√£o conclu√≠da com sucesso!\n",
      "\n",
      "üìö Para documenta√ß√£o completa: http://localhost:8000/docs\n"
     ]
    }
   ],
   "source": [
    "# Testando o endpoint atualizado de listagem de endpoints\n",
    "print(\"üìã 6. ENDPOINT ATUALIZADO DE LISTAGEM\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{API_BASE_URL}/endpoints\")\n",
    "    if response.status_code == 200:\n",
    "        endpoints_info = response.json()\n",
    "        print(\"‚úÖ Lista de endpoints atualizada obtida!\")\n",
    "        \n",
    "        # Informa√ß√µes da API\n",
    "        api_info = endpoints_info.get('api_info', {})\n",
    "        print(f\"\\nüìç {api_info.get('name', 'API')}\")\n",
    "        print(f\"üìå Vers√£o: {api_info.get('version', 'N/A')}\")\n",
    "        \n",
    "        # Contar endpoints\n",
    "        endpoints = endpoints_info.get('endpoints', {})\n",
    "        print(f\"\\nüîó ENDPOINTS DISPON√çVEIS ({len(endpoints)}):\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Organizar endpoints por categoria\n",
    "        get_endpoints = []\n",
    "        post_endpoints = []\n",
    "        \n",
    "        for name, details in endpoints.items():\n",
    "            method = details.get('method', 'N/A')\n",
    "            path = details.get('path', 'N/A')\n",
    "            description = details.get('description', 'N/A')\n",
    "            \n",
    "            endpoint_info = f\"‚Ä¢ {method:<6} {path}\\n  üìÑ {description}\"\n",
    "            \n",
    "            if method == 'GET':\n",
    "                get_endpoints.append(endpoint_info)\n",
    "            else:\n",
    "                post_endpoints.append(endpoint_info)\n",
    "        \n",
    "        print(\"üîç Endpoints GET:\")\n",
    "        for endpoint in get_endpoints:\n",
    "            print(endpoint)\n",
    "            print()\n",
    "        \n",
    "        print(\"üì§ Endpoints POST:\")\n",
    "        for endpoint in post_endpoints:\n",
    "            print(endpoint)\n",
    "            print()\n",
    "            \n",
    "        print(f\"üìä RESUMO:\")\n",
    "        print(f\"‚Ä¢ Total de endpoints: {len(endpoints)}\")\n",
    "        print(f\"‚Ä¢ Endpoints GET: {len(get_endpoints)}\")\n",
    "        print(f\"‚Ä¢ Endpoints POST: {len(post_endpoints)}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Erro: {response.status_code}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ TODOS OS NOVOS ENDPOINTS TESTADOS!\")\n",
    "print(\"‚úÖ Implementa√ß√£o conclu√≠da com sucesso!\")\n",
    "print(\"\\nüìö Para documenta√ß√£o completa: http://localhost:8000/docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7066063",
   "metadata": {},
   "source": [
    "### 8.1 Demonstra√ß√£o Completa com Dados Reais\n",
    "\n",
    "Vamos testar novamente com o arquivo CSV que cont√©m dados de funcion√°rios para ver os endpoints funcionando com dados reais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a7e6419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ DEMONSTRA√á√ÉO COM DADOS REAIS\n",
      "============================================================\n",
      "üìã DADOS DISPON√çVEIS:\n",
      "‚Ä¢ nome, idade, cidade, salario, departamento\n",
      "‚Ä¢ 10 registros de funcion√°rios\n",
      "\n",
      "üìä ESTAT√çSTICAS DETALHADAS\n",
      "----------------------------------------\n",
      "‚úÖ Estat√≠sticas obtidas com sucesso!\n",
      "üìä Total de vari√°veis: 5\n",
      "üî¢ Vari√°veis num√©ricas: 0\n",
      "üè∑Ô∏è Vari√°veis categ√≥ricas: 1\n",
      "\n",
      "üìà VARI√ÅVEIS NUM√âRICAS:\n",
      "\n",
      "üè∑Ô∏è VARI√ÅVEIS CATEG√ìRICAS:\n",
      "\n",
      "‚Ä¢ DEPARTAMENTO:\n",
      "  - Valores √∫nicos: 4\n",
      "  - % dados ausentes: 0.0%\n",
      "\n",
      "üîç AN√ÅLISE DE VARI√ÅVEL ESPEC√çFICA: 'idade'\n",
      "----------------------------------------\n",
      "‚úÖ An√°lise da vari√°vel 'idade' obtida!\n",
      "üè∑Ô∏è Tipo: Numeric\n",
      "‚ùå Dados ausentes: 0 (0.0%)\n",
      "\n",
      "üè∑Ô∏è AN√ÅLISE DE VARI√ÅVEL CATEG√ìRICA: 'departamento'\n",
      "----------------------------------------\n",
      "‚úÖ An√°lise da vari√°vel 'departamento' obtida!\n",
      "üè∑Ô∏è Tipo: Categorical\n",
      "üî¢ Valores √∫nicos: 4\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Demonstra√ß√£o completa com dados reais de funcion√°rios\n",
    "print(\"üéØ DEMONSTRA√á√ÉO COM DADOS REAIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Vamos primeiro ver que dados temos\n",
    "print(\"üìã DADOS DISPON√çVEIS:\")\n",
    "print(\"‚Ä¢ nome, idade, cidade, salario, departamento\")\n",
    "print(\"‚Ä¢ 10 registros de funcion√°rios\")\n",
    "\n",
    "# 1. Endpoint de Estat√≠sticas Detalhadas\n",
    "print(\"\\nüìä ESTAT√çSTICAS DETALHADAS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    with open('example_data.csv', 'rb') as file:\n",
    "        files = {'file': ('example_data.csv', file, 'text/csv')}\n",
    "        response = requests.post(f\"{API_BASE_URL}/statistics\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            stats_result = response.json()\n",
    "            print(\"‚úÖ Estat√≠sticas obtidas com sucesso!\")\n",
    "            \n",
    "            summary = stats_result['summary']\n",
    "            print(f\"üìä Total de vari√°veis: {summary['total_variables']}\")\n",
    "            print(f\"üî¢ Vari√°veis num√©ricas: {summary['numeric_count']}\")\n",
    "            print(f\"üè∑Ô∏è Vari√°veis categ√≥ricas: {summary['categorical_count']}\")\n",
    "            \n",
    "            # Estat√≠sticas num√©ricas\n",
    "            numeric_vars = stats_result.get('numeric_variables', {})\n",
    "            print(f\"\\nüìà VARI√ÅVEIS NUM√âRICAS:\")\n",
    "            for var_name, stats in numeric_vars.items():\n",
    "                print(f\"\\n‚Ä¢ {var_name.upper()}:\")\n",
    "                if isinstance(stats, dict):\n",
    "                    for key, value in stats.items():\n",
    "                        if isinstance(value, (int, float)):\n",
    "                            print(f\"  - {key}: {value:.2f}\")\n",
    "                        else:\n",
    "                            print(f\"  - {key}: {value}\")\n",
    "            \n",
    "            # Estat√≠sticas categ√≥ricas\n",
    "            categorical_vars = stats_result.get('categorical_variables', {})\n",
    "            print(f\"\\nüè∑Ô∏è VARI√ÅVEIS CATEG√ìRICAS:\")\n",
    "            for var_name, stats in categorical_vars.items():\n",
    "                print(f\"\\n‚Ä¢ {var_name.upper()}:\")\n",
    "                print(f\"  - Valores √∫nicos: {stats.get('n_distinct', 'N/A')}\")\n",
    "                print(f\"  - % dados ausentes: {stats.get('p_missing', 0) * 100:.1f}%\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"‚ùå Erro: {response.status_code} - {response.text}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "# 2. Testando an√°lise de vari√°vel espec√≠fica\n",
    "print(f\"\\nüîç AN√ÅLISE DE VARI√ÅVEL ESPEC√çFICA: 'idade'\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    with open('example_data.csv', 'rb') as file:\n",
    "        files = {'file': ('example_data.csv', file, 'text/csv')}\n",
    "        response = requests.post(f\"{API_BASE_URL}/variable/idade\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            var_result = response.json()\n",
    "            print(\"‚úÖ An√°lise da vari√°vel 'idade' obtida!\")\n",
    "            print(f\"üè∑Ô∏è Tipo: {var_result['variable_type']}\")\n",
    "            \n",
    "            missing_info = var_result['missing_info']\n",
    "            print(f\"‚ùå Dados ausentes: {missing_info['count']} ({missing_info['percentage']:.1f}%)\")\n",
    "            \n",
    "            # Estat√≠sticas detalhadas\n",
    "            analysis = var_result.get('analysis', {})\n",
    "            if 'description' in analysis:\n",
    "                desc = analysis['description']\n",
    "                print(f\"\\nüìä ESTAT√çSTICAS DA IDADE:\")\n",
    "                stats_keys = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "                for key in stats_keys:\n",
    "                    if key in desc:\n",
    "                        value = desc[key]\n",
    "                        if isinstance(value, float):\n",
    "                            print(f\"  - {key}: {value:.2f}\")\n",
    "                        else:\n",
    "                            print(f\"  - {key}: {value}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Erro: {response.status_code} - {response.text}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "# 3. Testando an√°lise de vari√°vel categ√≥rica\n",
    "print(f\"\\nüè∑Ô∏è AN√ÅLISE DE VARI√ÅVEL CATEG√ìRICA: 'departamento'\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    with open('example_data.csv', 'rb') as file:\n",
    "        files = {'file': ('example_data.csv', file, 'text/csv')}\n",
    "        response = requests.post(f\"{API_BASE_URL}/variable/departamento\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            var_result = response.json()\n",
    "            print(\"‚úÖ An√°lise da vari√°vel 'departamento' obtida!\")\n",
    "            print(f\"üè∑Ô∏è Tipo: {var_result['variable_type']}\")\n",
    "            \n",
    "            # An√°lise categ√≥rica\n",
    "            analysis = var_result.get('analysis', {})\n",
    "            print(f\"üî¢ Valores √∫nicos: {analysis.get('n_distinct', 'N/A')}\")\n",
    "            \n",
    "            # Frequ√™ncias se dispon√≠veis\n",
    "            if 'description' in analysis:\n",
    "                desc = analysis['description']\n",
    "                if 'value_counts_with_nan' in desc:\n",
    "                    print(f\"\\nüìä FREQU√äNCIA POR DEPARTAMENTO:\")\n",
    "                    for dept, count in desc['value_counts_with_nan'].items():\n",
    "                        print(f\"  - {dept}: {count} funcion√°rios\")\n",
    "        else:\n",
    "            print(f\"‚ùå Erro: {response.status_code} - {response.text}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ff61683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DEBUG - ESTRUTURA DOS DADOS EDA\n",
      "============================================================\n",
      "‚úÖ JSON bruto obtido com sucesso!\n",
      "üìã Chaves principais: ['filename', 'timestamp', 'analysis']\n",
      "üìä Chaves em 'analysis': ['filename', 'rows', 'columns', 'column_names', 'data_types', 'eda_report']\n",
      "‚ùå Chave 'variables' n√£o encontrada em 'analysis'\n",
      "\\n============================================================\n"
     ]
    }
   ],
   "source": [
    "# Debug - Vamos verificar a estrutura real dos dados EDA\n",
    "print(\"üîç DEBUG - ESTRUTURA DOS DADOS EDA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    with open('example_data.csv', 'rb') as file:\n",
    "        files = {'file': ('example_data.csv', file, 'text/csv')}\n",
    "        response = requests.post(f\"{API_BASE_URL}/upload-csv-raw\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            raw_result = response.json()\n",
    "            \n",
    "            print(\"‚úÖ JSON bruto obtido com sucesso!\")\n",
    "            print(f\"üìã Chaves principais: {list(raw_result.keys())}\")\n",
    "            \n",
    "            if 'analysis' in raw_result:\n",
    "                analysis = raw_result['analysis']\n",
    "                print(f\"üìä Chaves em 'analysis': {list(analysis.keys())}\")\n",
    "                \n",
    "                if 'variables' in analysis:\n",
    "                    variables = analysis['variables']\n",
    "                    print(f\"üìà Vari√°veis encontradas: {list(variables.keys())}\")\n",
    "                    \n",
    "                    # Mostrar estrutura de uma vari√°vel\n",
    "                    if variables:\n",
    "                        first_var = list(variables.keys())[0]\n",
    "                        var_structure = variables[first_var]\n",
    "                        print(f\"\\\\nüîç Estrutura da vari√°vel '{first_var}':\")\n",
    "                        print(f\"Chaves: {list(var_structure.keys())}\")\n",
    "                        \n",
    "                        # Mostrar tipo\n",
    "                        print(f\"Tipo: {var_structure.get('type', 'N/A')}\")\n",
    "                        \n",
    "                        # Mostrar algumas propriedades\n",
    "                        for key in ['n_missing', 'p_missing', 'n_distinct']:\n",
    "                            if key in var_structure:\n",
    "                                print(f\"{key}: {var_structure[key]}\")\n",
    "                else:\n",
    "                    print(\"‚ùå Chave 'variables' n√£o encontrada em 'analysis'\")\n",
    "            else:\n",
    "                print(\"‚ùå Chave 'analysis' n√£o encontrada\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"‚ùå Erro: {response.status_code} - {response.text}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b301818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• DEMONSTRA√á√ÉO FINAL - CORRELA√á√ïES E VISUALIZA√á√ïES\n",
      "============================================================\n",
      "üîó MATRIZ DE CORRELA√á√ïES\n",
      "----------------------------------------\n",
      "‚úÖ Correla√ß√µes obtidas!\n",
      "üîó Tipos dispon√≠veis: ['auto', 'pearson', 'spearman', 'phi_k']\n",
      "\n",
      "üìä Matriz AUTO:\n",
      "  - Dimens√µes: 3x3\n",
      "\n",
      "üìä Matriz PEARSON:\n",
      "  - Dimens√µes: 2x2\n",
      "\n",
      "üìä Matriz SPEARMAN:\n",
      "  - Dimens√µes: 2x2\n",
      "\n",
      "üìä Matriz PHI_K:\n",
      "  - Dimens√µes: 5x5\n",
      "\n",
      "üé® VISUALIZA√á√ïES SVG\n",
      "----------------------------------------\n",
      "‚úÖ Visualiza√ß√µes extra√≠das!\n",
      "üé® Total: 0\n",
      "üéØ Tipos: []\n",
      "\n",
      "üí∞ AN√ÅLISE DETALHADA: 'salario'\n",
      "----------------------------------------\n",
      "‚úÖ An√°lise do sal√°rio obtida!\n",
      "üè∑Ô∏è Tipo: Numeric\n",
      "\n",
      "============================================================\n",
      "üéâ DEMONSTRA√á√ÉO COMPLETA DOS NOVOS ENDPOINTS!\n",
      "üìä Resumo dos endpoints implementados:\n",
      "  ‚úÖ /correlations - Matrizes de correla√ß√£o\n",
      "  ‚úÖ /statistics - Estat√≠sticas descritivas\n",
      "  ‚úÖ /alerts - Alertas de qualidade\n",
      "  ‚úÖ /visualizations - Extra√ß√£o de SVGs\n",
      "  ‚úÖ /variable/{name} - An√°lise de vari√°vel espec√≠fica\n",
      "\n",
      "üåê Acesse a documenta√ß√£o: http://localhost:8000/docs\n"
     ]
    }
   ],
   "source": [
    "# Demonstra√ß√£o final dos endpoints restantes\n",
    "print(\"üî• DEMONSTRA√á√ÉO FINAL - CORRELA√á√ïES E VISUALIZA√á√ïES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Testando correla√ß√µes\n",
    "print(\"üîó MATRIZ DE CORRELA√á√ïES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    with open('example_data.csv', 'rb') as file:\n",
    "        files = {'file': ('example_data.csv', file, 'text/csv')}\n",
    "        response = requests.post(f\"{API_BASE_URL}/correlations\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            corr_result = response.json()\n",
    "            print(\"‚úÖ Correla√ß√µes obtidas!\")\n",
    "            print(f\"üîó Tipos dispon√≠veis: {corr_result['available_types']}\")\n",
    "            \n",
    "            correlations = corr_result.get('correlations', {})\n",
    "            for corr_type, matrix in correlations.items():\n",
    "                if matrix:\n",
    "                    print(f\"\\nüìä Matriz {corr_type.upper()}:\")\n",
    "                    print(f\"  - Dimens√µes: {len(matrix)}x{len(matrix[0]) if matrix else 0}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Erro: {response.status_code}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "# 2. Testando visualiza√ß√µes\n",
    "print(f\"\\nüé® VISUALIZA√á√ïES SVG\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    with open('example_data.csv', 'rb') as file:\n",
    "        files = {'file': ('example_data.csv', file, 'text/csv')}\n",
    "        response = requests.post(f\"{API_BASE_URL}/visualizations\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            viz_result = response.json()\n",
    "            summary = viz_result['summary']\n",
    "            \n",
    "            print(\"‚úÖ Visualiza√ß√µes extra√≠das!\")\n",
    "            print(f\"üé® Total: {summary['total_visualizations']}\")\n",
    "            print(f\"üéØ Tipos: {summary['available_types']}\")\n",
    "            \n",
    "            visualizations = viz_result.get('visualizations', {})\n",
    "            if visualizations:\n",
    "                print(f\"\\nüñºÔ∏è Visualiza√ß√µes encontradas:\")\n",
    "                for i, (path, svg) in enumerate(list(visualizations.items())[:3], 1):\n",
    "                    print(f\"{i}. {path} ({len(svg):,} caracteres)\")\n",
    "        else:\n",
    "            print(f\"‚ùå Erro: {response.status_code}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "# 3. Testando an√°lise de vari√°vel 'salario'\n",
    "print(f\"\\nüí∞ AN√ÅLISE DETALHADA: 'salario'\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    with open('example_data.csv', 'rb') as file:\n",
    "        files = {'file': ('example_data.csv', file, 'text/csv')}\n",
    "        response = requests.post(f\"{API_BASE_URL}/variable/salario\", files=files)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            var_result = response.json()\n",
    "            print(\"‚úÖ An√°lise do sal√°rio obtida!\")\n",
    "            print(f\"üè∑Ô∏è Tipo: {var_result['variable_type']}\")\n",
    "            \n",
    "            # Estat√≠sticas do sal√°rio\n",
    "            analysis = var_result.get('analysis', {})\n",
    "            if 'description' in analysis:\n",
    "                desc = analysis['description']\n",
    "                print(f\"\\nüí∞ ESTAT√çSTICAS SALARIAIS:\")\n",
    "                \n",
    "                stats_map = {\n",
    "                    'count': 'Total de funcion√°rios',\n",
    "                    'mean': 'Sal√°rio m√©dio',\n",
    "                    'std': 'Desvio padr√£o',\n",
    "                    'min': 'Menor sal√°rio',\n",
    "                    '25%': '1¬∫ Quartil',\n",
    "                    '50%': 'Mediana',\n",
    "                    '75%': '3¬∫ Quartil',\n",
    "                    'max': 'Maior sal√°rio'\n",
    "                }\n",
    "                \n",
    "                for key, label in stats_map.items():\n",
    "                    if key in desc:\n",
    "                        value = desc[key]\n",
    "                        if key == 'count':\n",
    "                            print(f\"  - {label}: {int(value)}\")\n",
    "                        else:\n",
    "                            print(f\"  - {label}: R$ {value:,.2f}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Erro: {response.status_code} - {response.text}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ DEMONSTRA√á√ÉO COMPLETA DOS NOVOS ENDPOINTS!\")\n",
    "print(\"üìä Resumo dos endpoints implementados:\")\n",
    "print(\"  ‚úÖ /correlations - Matrizes de correla√ß√£o\")\n",
    "print(\"  ‚úÖ /statistics - Estat√≠sticas descritivas\")\n",
    "print(\"  ‚úÖ /alerts - Alertas de qualidade\")\n",
    "print(\"  ‚úÖ /visualizations - Extra√ß√£o de SVGs\")\n",
    "print(\"  ‚úÖ /variable/{name} - An√°lise de vari√°vel espec√≠fica\")\n",
    "print(f\"\\nüåê Acesse a documenta√ß√£o: http://localhost:8000/docs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda-backend-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
